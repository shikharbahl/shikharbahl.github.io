<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta http-equiv="refresh" content="0; URL='http://www.cs.cmu.edu/~sbahl2/'" />
  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    a {
      color: #1772d0;
      text-decoration: none;
    }

    a:focus,
    a:hover {
      color: #f09220;
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 400
    }

    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 600
    }

    heading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 600
    }

    papertitle {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 600
    }

    name {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 32px;
      font-weight: 400
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/ri_logo.png">
  <title>Shikhar Bahl</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <!-- <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'> -->
  <link href="https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic" rel="stylesheet" type="text/css">
</head>

<body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Shikhar Bahl</name>
              </p>
              <p>Hi there! I am a first year PhD student at the <a href="https://www.ri.cmu.edu/">Robotics Institute</a>, within the <a href="https://www.cs.cmu.edu/"> School of Computer Science</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>. I am interested in artificial intelligence, machine learning and robotics.
                I am advised by <a href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a> and <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a>. </p>

                <p> Prior to CMU, I did my undergrad at <a href="https://www.berkeley.edu/">UC Berkeley</a> in Applied Math and Computer Science, where I was affiliated with <a href="https://bair.berkeley.edu/">Berkeley Artificial Intelligence Research</a> (BAIR) and worked under <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a> on problems in deep reinforcement learning and robotics.
              </p>


              <p> Feel free to contact me via email! You can reach me at sbahl2 -at- cs dot cmu dot edu</p>


              <p align=center>
                <!-- <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="mailto:sbahl2@andrew.cmu.edu">email</a> &nbsp/&nbsp
                <a href="data/shikharCV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=bdHgGgEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/shikharbahl"> Twitter </a> &nbsp/&nbsp
                <a href="https://github.com/shikharbahl">GitHub</a>
              </p>
            </td>
            <td width="33%">
              <img src="images/rsz_shikhar_bahl_circle.png">
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Research</heading>
              <p>
                I am broadly interested in creating robust autonomous agents that operate with minimal or no human supervision. My research focuses on combining machine learning, reinforcement learning, computer vision and perception for robotic control. Here is some of my work:
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <tr>
            <td width="25%"><img src="images/visual_natural_reward.png" width="220"  height="100" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="https://arxiv.org/pdf/1906.05841.pdf">
                    <papertitle>Deep Reinforcement Learning for Industrial Insertion Tasks with Visual Inputs and Natural Rewards</papertitle>
                  </a>
                  <br>
                  Gerrit Schoettler*, <a href="http://ashvin.me/">Ashvin Nair*</a>, Jianlan Luo, <strong>Shikhar Bahl</strong>, Juan aparicio Ojea, Eugen Solowjow, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                  <br>
                  <em> IROS, </em> 2020
                  <br>
                  <a href="https://arxiv.org/pdf/1906.05841.pdf">pdf</a> | <a href="https://industrial-insertion-rl.github.io/">project page</a>
                  <!-- <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
                  <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a> -->
                </p>
                <!-- <p>
                  We consider a variety of difficult industrial insertion tasks with visual inputs and different natural reward specifications, namely sparse rewards and goal images. We show that methods that combine RL with prior information, such as classical controllers or demonstrations, can solve these tasks from a reasonable amount of real-world interaction.
                </p> -->
              </td>
          </tr>


          <tr>
            <td width="25%"><img src="images/skewfit_new.png" width="190" height="140" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="https://arxiv.org/pdf/1903.03698.pdf">
                    <papertitle>Skew-Fit: State-Covering Self-Supervised Reinforcement Learning</papertitle>
                  </a>
                  <br>
                  <a href="http://people.eecs.berkeley.edu/~vitchyr/">Vitchyr H. Pong*</a>, Murtaza Dalal*, Steven Lin*, <a href="http://ashvin.me/">Ashvin Nair</a>, <strong>Shikhar Bahl</strong>, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                  <br>
                  <em> ICML,</em> 2020
                  <br>
                  <a href="https://arxiv.org/pdf/1903.03698.pdf">pdf</a> | <a href="https://sites.google.com/view/skew-fit">project page</a>
                  <!-- <a href="data/ArbelaezCVPR2014.bib">bibtex</a> -->
                </p>
                <!-- <p> We present an algorithm called Skew-Fit for learning such a maximum-entropy goal distribution.
                </p>
                <br>
                </p> -->
              </td>
          </tr>


          <tr>
            <td width="25%"><img src="images/ccrig.png" width="240"  height="120" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="http://proceedings.mlr.press/v100/nair20a/nair20a.pdf">
                    <papertitle> Contextual Imagined Goals for Self-Supervised Robotic Learning</papertitle>
                  </a>
                  <br>
                  <a href="http://ashvin.me/">Ashvin Nair*</a>, <strong>Shikhar Bahl*</strong>, Alexander Khazatsky*, <a href="http://people.eecs.berkeley.edu/~vitchyr/">Vitchyr H. Pong</a>, <a href="https://people.eecs.berkeley.edu/~gberseth/"> Glen Berseth </a>, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                  <!-- <br>
                  <em>arXiv preprint</em>
                  <br> -->
                  <br>
                  <em> CoRL, </em> 2019
                  <br>
                  <a href="https://arxiv.org/pdf/1906.05841.pdf">pdf</a> | <a href="https://industrial-insertion-rl.github.io/">project page</a>
                  <!-- <a href="data/PontTusetTPAMI2017.bib">bibtex</a> /
                  <a href="https://drive.google.com/file/d/1AiB78Fy7QVA3KqgcooyzMAC5L8HhNzjz/view?usp=sharing">fast eigenvector code</a> -->
                </p>
                <!-- <p>
                  We propose a conditional goal-setting model that aims to only propose goals that are feasible reachable from the robot's current state, and demonstrate that this enables self-supervised goal-conditioned learning with raw image observations both in varied simulated environments and a real-world pushing task.
                </p> -->
              </td>
          </tr>

          <tr>
            <td width="25%"><img src="images/residual.png" width="240" style="border-style: none">
              <td width="75%" valign="top">
                <p>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794127">
                    <papertitle>Residual Reinforcement Learning for Robot Control</papertitle>
                  </a>
                  <br>
                  Tobias Johannink*, <strong>Shikhar Bahl*</strong>, <a href="http://ashvin.me/">Ashvin Nair*</a>, Jianlan Luo, Avinash Kumar, Matthias Loskyll, Juan Aparicio Ojea,  Eugen Solowjow, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                  <br>
                  <em> ICRA, </em> 2019

                  <br>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794127">pdf</a> | <a href="https://residualrl.github.io/">project page</a>
                  <!-- <br>
                  <!-- <a href="http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/mcg/">project page</a> /
                  <a href="data/ArbelaezCVPR2014.bib">bibtex</a> -->
                </p>
                <!-- <p> We study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the residual which is solved with RL. The final control policy is a superposition of both control signals. We demonstrate our approach by training an agent to successfully perform a real-world block assembly task involving contacts and unstable objects -->
                <!-- </p>
                <br>
                </p> -->
              </td>
          </tr>


          <tr>
              <td width="25%"><img src="images/rig.png" width="250"  style="border-style: none">
                <td width="75%" valign="top">
                  <p>
                    <a href="http://papers.nips.cc/paper/8132-visual-reinforcement-learning-with-imagined-goals.pdf">
                      <papertitle>Visual Reinforcement Learning with Imagined Goals</papertitle>
                    </a>
                    <br>
                    <a href="http://ashvin.me/">Ashvin Nair*</a>, <a href="http://people.eecs.berkeley.edu/~vitchyr/">Vitchyr H. Pong*</a>, Murtaza Dalal, <strong>Shikhar Bahl</strong>, Steven Lin, <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
                    <br>
                    <em> NeurIPS, </em> 2018  <font color="red"><strong>(Spotlight Presentation)</strong></font>
                    <br>
                    <a href="http://papers.nips.cc/paper/8132-visual-reinforcement-learning-with-imagined-goals.pdf">pdf</a> | <a href="https://sites.google.com/site/visualrlwithimaginedgoals/">project page</a>
                    <!-- <a href="data/ArbelaezCVPR2014.bib">bibtex</a> -->
                  </p>
                  <!-- <p> We propose an algorithm that acquires such general-purpose skills by combining unsupervised representation learning and reinforcement learning of goal-conditioned policies.
                  </p>
                  <br>
                  </p> -->
                </td>
            </tr>








        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="20">
          <tr>
            <td width="25%"><img src="images/SparseGraphSenators.png" width="160" height="160"></td>
            <td width="75%" valign="center">
              <p>
                <a href="https://people.eecs.berkeley.edu/~elghaoui/Teaching/EECS127/">
                  <papertitle>EECS127 - Fall 2018 (uGSI)</papertitle>
                </a>
              </p>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                    Website template from this <a href="https://github.com/jonbarron/jonbarron_website"><strong>repo</strong></a> and this <a href="https://www.cs.cmu.edu/~dpathak/"><strong>webpage</strong></a>!
                  </font>
              </p>
            </td>
          </tr>
        </table>
        <script type="text/javascript">
          var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
        </script>
        <script type="text/javascript">
          try {
            var pageTracker = _gat._getTracker("UA-7580334-1");
            pageTracker._trackPageview();
          } catch (err) {}
        </script>
        </td>
    </tr>
  </table>
</body>

</html>
